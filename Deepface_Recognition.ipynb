{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0397562f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ACER\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "=== DeepFace Face Detection ===\n",
      "1. Analyze from image\n",
      "2. Analyze from video\n",
      "3. Analyze from webcam\n",
      "4. Exit\n",
      "üëã K·∫øt th√∫c ch∆∞∆°ng tr√¨nh.\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "import cv2\n",
    "import os\n",
    "import datetime\n",
    "import platform\n",
    "\n",
    "def is_gui_available():\n",
    "    return platform.system() != \"Linux\" or os.environ.get(\"DISPLAY\") is not None\n",
    "\n",
    "def analyze_and_draw(frame):\n",
    "    try:\n",
    "        results = DeepFace.analyze(frame, actions=[\"age\", \"gender\", \"emotion\"], enforce_detection=False)\n",
    "        y_label = 30  \n",
    "        for face in results:\n",
    "            region = face.get(\"region\", {})\n",
    "            if not region:\n",
    "                continue\n",
    "            x = region.get(\"x\", 0)\n",
    "            y = region.get(\"y\", 0)\n",
    "            w = region.get(\"w\", 0)\n",
    "            h = region.get(\"h\", 0)\n",
    "\n",
    "            gender_data = face.get(\"gender\", {})\n",
    "            gender = max(gender_data, key=gender_data.get) if isinstance(gender_data, dict) else str(gender_data)\n",
    "            age = str(face.get(\"age\", \"?\"))\n",
    "            emotion = str(face.get(\"dominant_emotion\", \"?\"))\n",
    "            label = f\"Gender: {gender} | Age: {age} | Emotion: {emotion}\"\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (10, y_label), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "            y_label += 30 \n",
    "    except Exception as e:\n",
    "        print(\"L·ªói ph√¢n t√≠ch g∆∞∆°ng m·∫∑t:\", e)\n",
    "    return frame\n",
    "\n",
    "def create_output_dir():\n",
    "    os.makedirs(\"result_deepface\", exist_ok=True)\n",
    "    return \"result_deepface\"\n",
    "\n",
    "def analyze_from_image(image_path):\n",
    "    if not os.path.exists(image_path):\n",
    "        print(\"Kh√¥ng t√¨m th·∫•y ·∫£nh:\", image_path)\n",
    "        return\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    result = analyze_and_draw(image)\n",
    "\n",
    "    if is_gui_available():\n",
    "        cv2.imshow(\"Result from image\", result)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    output_path = os.path.join(create_output_dir(), f\"deepface_{os.path.basename(image_path)}\")\n",
    "    cv2.imwrite(output_path, result)\n",
    "    print(f\" ·∫¢nh k·∫øt qu·∫£ ƒë√£ l∆∞u t·∫°i: {output_path}\")\n",
    "\n",
    "def analyze_from_video(video_path):\n",
    "    if not os.path.exists(video_path):\n",
    "        print(\"Kh√¥ng t√¨m th·∫•y video:\", video_path)\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Kh√¥ng m·ªü ƒë∆∞·ª£c video.\")\n",
    "        return\n",
    "\n",
    "    output_dir = create_output_dir()\n",
    "    last_result = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        result = analyze_and_draw(frame)\n",
    "        last_result = result.copy()\n",
    "\n",
    "        if is_gui_available():\n",
    "            cv2.imshow(\"DeepFace video\", result)\n",
    "\n",
    "        if is_gui_available() and cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    if is_gui_available():\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    if last_result is not None:\n",
    "        filename = f\"deepface_video_lastframe_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg\"\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        cv2.imwrite(output_path, last_result)\n",
    "        print(f\" ƒê√£ l∆∞u frame cu·ªëi c√πng t·ª´ video: {output_path}\")\n",
    "    print(\"ƒê√£ k·∫øt th√∫c ph√¢n t√≠ch video.\")\n",
    "\n",
    "def analyze_from_webcam():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Kh√¥ng th·ªÉ m·ªü webcam.\")\n",
    "        return\n",
    "\n",
    "    output_dir = create_output_dir()\n",
    "    analyzed_frame = None\n",
    "\n",
    "    print(\"üì° ƒêang ph√¢n t√≠ch t·ª´ webcam... Nh·∫•n 'e' ho·∫∑c 'ESC' ƒë·ªÉ tho√°t.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            results = DeepFace.analyze(frame, actions=[\"age\", \"gender\", \"emotion\"], enforce_detection=False)\n",
    "            y_label = 30\n",
    "            for face in results:\n",
    "                region = face.get(\"region\", {})\n",
    "                if not region:\n",
    "                    continue\n",
    "                x = region.get(\"x\", 0)\n",
    "                y = region.get(\"y\", 0)\n",
    "                w = region.get(\"w\", 0)\n",
    "                h = region.get(\"h\", 0)\n",
    "\n",
    "                gender_data = face.get(\"gender\", {})\n",
    "                gender = max(gender_data, key=gender_data.get) if isinstance(gender_data, dict) else str(gender_data)\n",
    "                age = str(face.get(\"age\", \"?\"))\n",
    "                emotion = str(face.get(\"dominant_emotion\", \"?\"))\n",
    "                label = f\"Gender: {gender} | Age: {age} | Emotion: {emotion}\"\n",
    "\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, label, (10, y_label), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "                y_label += 30\n",
    "\n",
    "            analyzed_frame = frame.copy()\n",
    "        except Exception as e:\n",
    "            print(\" L·ªói ph√¢n t√≠ch:\", e)\n",
    "\n",
    "        if is_gui_available():\n",
    "            cv2.imshow(\"DeepFace webcam\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27 or key == ord('e'):\n",
    "            print(\"ƒê√£ tho√°t webcam.\")\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    if is_gui_available():\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    if analyzed_frame is not None:\n",
    "        filename = f\"deepface_webcam_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg\"\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        cv2.imwrite(output_path, analyzed_frame)\n",
    "        print(f\" ƒê√£ l∆∞u ·∫£nh cu·ªëi c√πng t·ª´ webcam: {output_path}\")\n",
    "    else:\n",
    "        print(\" Kh√¥ng c√≥ ·∫£nh n√†o ƒë∆∞·ª£c l∆∞u.\")\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        print(\"\\n=== DeepFace Face Detection ===\")\n",
    "        print(\"1. Analyze from image\")\n",
    "        print(\"2. Analyze from video\")\n",
    "        print(\"3. Analyze from webcam\")\n",
    "        print(\"4. Exit\")\n",
    "        choice = input(\" Nh·∫≠p l·ª±a ch·ªçn (1/2/3/4): \")\n",
    "\n",
    "        if choice == '1':\n",
    "            path = input(\" Nh·∫≠p ƒë∆∞·ªùng d·∫´n ·∫£nh: \")\n",
    "            analyze_from_image(path)\n",
    "        elif choice == '2':\n",
    "            path = input(\"üéûÔ∏è Nh·∫≠p ƒë∆∞·ªùng d·∫´n video: \")\n",
    "            analyze_from_video(path)\n",
    "        elif choice == '3':\n",
    "            analyze_from_webcam()\n",
    "        elif choice == '4':\n",
    "            print(\" K·∫øt th√∫c ch∆∞∆°ng tr√¨nh.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\" L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b86542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
