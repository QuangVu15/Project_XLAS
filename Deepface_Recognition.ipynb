{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0397562f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ACER\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "25-07-14 16:04:42 - Directory C:\\Users\\ACER\\.deepface has been created\n",
      "25-07-14 16:04:42 - Directory C:\\Users\\ACER\\.deepface\\weights has been created\n",
      "\n",
      "=== DeepFace Face Detection ===\n",
      "1. Analyze from image\n",
      "2. Analyze from video\n",
      "3. Analyze from webcam\n",
      "4. Exit\n",
      "üëã K·∫øt th√∫c ch∆∞∆°ng tr√¨nh.\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "import cv2\n",
    "import os\n",
    "import datetime\n",
    "import platform\n",
    "\n",
    "# Ki·ªÉm tra xem c√≥ th·ªÉ hi·ªÉn th·ªã GUI kh√¥ng (d√πng cho Jupyter ho·∫∑c h·ªá th·ªëng kh√¥ng c√≥ m√†n h√¨nh)\n",
    "def is_gui_available():\n",
    "    return platform.system() != \"Linux\" or os.environ.get(\"DISPLAY\") is not None\n",
    "\n",
    "# -----------------------------------------------\n",
    "# H√†m ph√¢n t√≠ch DeepFace tr√™n m·ªôt frame ·∫£nh\n",
    "# -----------------------------------------------\n",
    "def analyze_and_draw(frame):\n",
    "    try:\n",
    "        results = DeepFace.analyze(frame, actions=[\"age\", \"gender\", \"emotion\"], enforce_detection=False)\n",
    "        for face in results:\n",
    "            region = face.get(\"region\", {})\n",
    "            if not region: continue\n",
    "            x, y, w, h = region.values()\n",
    "\n",
    "            gender = face.get(\"gender\", \"?\")\n",
    "            age = face.get(\"age\", \"?\")\n",
    "            emotion = face.get(\"dominant_emotion\", \"?\")\n",
    "\n",
    "            # V·∫Ω khung\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            label = f\"{gender}, {age}, {emotion}\"\n",
    "            cv2.putText(frame, label, (x, y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è L·ªói ph√¢n t√≠ch g∆∞∆°ng m·∫∑t:\", e)\n",
    "    return frame\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£\n",
    "def create_output_dir():\n",
    "    os.makedirs(\"result_deepface\", exist_ok=True)\n",
    "    return \"result_deepface\"\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 1. Ph√¢n t√≠ch t·ª´ ·∫£nh\n",
    "# -----------------------------------------------\n",
    "def analyze_from_image(image_path):\n",
    "    if not os.path.exists(image_path):\n",
    "        print(\" Kh√¥ng t√¨m th·∫•y ·∫£nh:\", image_path)\n",
    "        return\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    result = analyze_and_draw(image)\n",
    "\n",
    "    if is_gui_available():\n",
    "        cv2.imshow(\"Result from image\", result)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    output_dir = create_output_dir()\n",
    "    output_path = os.path.join(output_dir, f\"deepface_{os.path.basename(image_path)}\")\n",
    "    cv2.imwrite(output_path, result)\n",
    "    print(f\"üíæ ·∫¢nh k·∫øt qu·∫£ ƒë√£ l∆∞u t·∫°i: {output_path}\")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 2. Ph√¢n t√≠ch t·ª´ video\n",
    "# -----------------------------------------------\n",
    "def analyze_from_video(video_path):\n",
    "    if not os.path.exists(video_path):\n",
    "        print(\" Kh√¥ng t√¨m th·∫•y video:\", video_path)\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\" Kh√¥ng m·ªü ƒë∆∞·ª£c video.\")\n",
    "        return\n",
    "\n",
    "    output_dir = create_output_dir()\n",
    "    frame_id = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_id += 1\n",
    "        result = analyze_and_draw(frame)\n",
    "\n",
    "        if is_gui_available():\n",
    "            cv2.imshow(\"DeepFace video\", result)\n",
    "\n",
    "        # L∆∞u t·ª´ng frame\n",
    "        filename = f\"{output_dir}/deepface_frame_{frame_id}.jpg\"\n",
    "        cv2.imwrite(filename, result)\n",
    "\n",
    "        if is_gui_available() and cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    if is_gui_available():\n",
    "        cv2.destroyAllWindows()\n",
    "    print(\" ƒê√£ k·∫øt th√∫c ph√¢n t√≠ch video.\")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 3. Ph√¢n t√≠ch t·ª´ webcam\n",
    "# -----------------------------------------------\n",
    "def analyze_from_webcam():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\" Kh√¥ng th·ªÉ m·ªü webcam.\")\n",
    "        return\n",
    "\n",
    "    output_dir = create_output_dir()\n",
    "    frame_id = 0\n",
    "    saved_count = 0\n",
    "\n",
    "    print(\"üì° ƒêang ph√¢n t√≠ch t·ª´ webcam... Nh·∫•n 'e' ƒë·ªÉ tho√°t.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_id += 1\n",
    "        try:\n",
    "            results = DeepFace.analyze(frame, actions=[\"age\", \"gender\", \"emotion\"], enforce_detection=False)\n",
    "            if results:\n",
    "                for face in results:\n",
    "                    region = face.get(\"region\", {})\n",
    "                    if not region: continue\n",
    "                    x, y, w, h = region.values()\n",
    "                    gender = face.get(\"gender\", \"?\")\n",
    "                    age = face.get(\"age\", \"?\")\n",
    "                    emotion = face.get(\"dominant_emotion\", \"?\")\n",
    "\n",
    "                    # V·∫Ω khung v√† label\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    label = f\"{gender}, {age}, {emotion}\"\n",
    "                    cv2.putText(frame, label, (x, y - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "                # L∆∞u ·∫£nh c√≥ khu√¥n m·∫∑t\n",
    "                saved_count += 1\n",
    "                filename = f\"{output_dir}/deepface_webcam_{frame_id}.jpg\"\n",
    "                cv2.imwrite(filename, frame)\n",
    "                print(f\"üíæ ƒê√£ l∆∞u ·∫£nh c√≥ khu√¥n m·∫∑t: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(\" L·ªói ph√¢n t√≠ch:\", e)\n",
    "\n",
    "        if is_gui_available():\n",
    "            cv2.imshow(\"DeepFace webcam\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('e') or key == 27:\n",
    "            print(\" ƒê√£ tho√°t webcam.\")\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    if is_gui_available():\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\" T·ªïng s·ªë ·∫£nh ch·ª©a khu√¥n m·∫∑t ƒë√£ l∆∞u: {saved_count}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Menu ch√≠nh\n",
    "# -----------------------------------------------\n",
    "def main():\n",
    "    while True:\n",
    "        print(\"\\n=== DeepFace Face Detection ===\")\n",
    "        print(\"1. Analyze from image\")\n",
    "        print(\"2. Analyze from video\")\n",
    "        print(\"3. Analyze from webcam\")\n",
    "        print(\"4. Exit\")\n",
    "        choice = input(\"üëâ Nh·∫≠p l·ª±a ch·ªçn (1/2/3/4): \")\n",
    "\n",
    "        if choice == '1':\n",
    "            path = input(\"üñºÔ∏è Nh·∫≠p ƒë∆∞·ªùng d·∫´n ·∫£nh: \")\n",
    "            analyze_from_image(path)\n",
    "        elif choice == '2':\n",
    "            path = input(\"üéûÔ∏è Nh·∫≠p ƒë∆∞·ªùng d·∫´n video: \")\n",
    "            analyze_from_video(path)\n",
    "        elif choice == '3':\n",
    "            analyze_from_webcam()\n",
    "        elif choice == '4':\n",
    "            print(\"üëã K·∫øt th√∫c ch∆∞∆°ng tr√¨nh.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
